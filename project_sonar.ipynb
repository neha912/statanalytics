{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "from sklearn import  metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knnc\n",
    "from sklearn.naive_bayes import GaussianNB as gnb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sonar_data.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.columns[len(data.columns)-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "165  0.0221  0.0065  0.0164  0.0487  0.0519  0.0849  0.0812  0.1833  0.2228   \n",
       "167  0.0137  0.0297  0.0116  0.0082  0.0241  0.0253  0.0279  0.0130  0.0489   \n",
       "72   0.0208  0.0186  0.0131  0.0211  0.0610  0.0613  0.0612  0.0506  0.0989   \n",
       "107  0.0428  0.0555  0.0708  0.0618  0.1215  0.1524  0.1543  0.0391  0.0610   \n",
       "128  0.0374  0.0586  0.0628  0.0534  0.0255  0.1422  0.2072  0.2734  0.3070   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15   0.0298  0.0615  0.0650  0.0921  0.1615  0.2294  0.2176  0.2033  0.1459   \n",
       "198  0.0238  0.0318  0.0422  0.0399  0.0788  0.0766  0.0881  0.1143  0.1594   \n",
       "162  0.0217  0.0152  0.0346  0.0346  0.0484  0.0526  0.0773  0.0862  0.1451   \n",
       "74   0.0109  0.0093  0.0121  0.0378  0.0679  0.0863  0.1004  0.0664  0.0941   \n",
       "96   0.0181  0.0146  0.0026  0.0141  0.0421  0.0473  0.0361  0.0741  0.1398   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "165  0.1810  ...  0.0167  0.0089  0.0051  0.0015  0.0075  0.0058  0.0016   \n",
       "167  0.0874  ...  0.0169  0.0081  0.0040  0.0025  0.0036  0.0058  0.0067   \n",
       "72   0.1093  ...  0.0140  0.0074  0.0063  0.0081  0.0087  0.0044  0.0028   \n",
       "107  0.0113  ...  0.0009  0.0142  0.0179  0.0079  0.0060  0.0131  0.0089   \n",
       "128  0.2597  ...  0.0353  0.0118  0.0063  0.0237  0.0032  0.0087  0.0124   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15   0.0852  ...  0.0154  0.0031  0.0153  0.0071  0.0212  0.0076  0.0152   \n",
       "198  0.2048  ...  0.0186  0.0096  0.0071  0.0084  0.0038  0.0026  0.0028   \n",
       "162  0.2110  ...  0.0205  0.0123  0.0067  0.0011  0.0026  0.0049  0.0029   \n",
       "74   0.1036  ...  0.0124  0.0077  0.0023  0.0117  0.0053  0.0077  0.0076   \n",
       "96   0.1045  ...  0.0076  0.0223  0.0255  0.0145  0.0233  0.0041  0.0018   \n",
       "\n",
       "         57      58      59  \n",
       "165  0.0070  0.0074  0.0038  \n",
       "167  0.0035  0.0043  0.0033  \n",
       "72   0.0019  0.0049  0.0023  \n",
       "107  0.0084  0.0113  0.0049  \n",
       "128  0.0113  0.0098  0.0126  \n",
       "..      ...     ...     ...  \n",
       "15   0.0049  0.0200  0.0073  \n",
       "198  0.0013  0.0035  0.0060  \n",
       "162  0.0022  0.0022  0.0032  \n",
       "74   0.0056  0.0055  0.0039  \n",
       "96   0.0048  0.0089  0.0085  \n",
       "\n",
       "[208 rows x 60 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(frac =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.22,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    knnc(),\n",
    "    dtc(),\n",
    "    SVC(),\n",
    "    SVC(kernel='linear'),\n",
    "    gnb()\n",
    "]\n",
    "classifier_names = [\n",
    "    'K nearest neighbors',\n",
    "    'Decision Tree Classifier',\n",
    "    'SVM classifier with RBF kernel',\n",
    "    'SVM classifier with linear kernel',\n",
    "    'Gaussian Naive Bayes'\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K nearest neighbors  mean accuracy:  75.919 % std:  0.885 %\n",
      "Decision Tree Classifier  mean accuracy:  75.257 % std:  0.979 %\n",
      "SVM classifier with RBF kernel  mean accuracy:  75.993 % std:  1.282 %\n",
      "SVM classifier with linear kernel  mean accuracy:  72.831 % std:  0.17 %\n",
      "Gaussian Naive Bayes  mean accuracy:  68.971 % std:  1.62 %\n"
     ]
    }
   ],
   "source": [
    "for clf, clf_name in zip(classifiers, classifier_names):\n",
    "    cv_scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "    \n",
    "    print(clf_name, ' mean accuracy: ', round(cv_scores.mean()*100, 3), '% std: ', round(cv_scores.var()*100, 3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:-1].astype(float)\n",
    "Y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, set_option\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check some algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.769485 (0.100510)\n",
      "LDA: 0.752574 (0.107741)\n",
      "KNN: 0.808088 (0.067507)\n",
      "CART: 0.693382 (0.065462)\n",
      "NB: 0.642647 (0.149464)\n",
      "SVM: 0.776471 (0.090411)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.868015 using {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.872426 using {'C': 1.7, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#17 0.770221 (0.095521) with: {'C': 0.1, 'kernel': 'linear'}\n",
      "#40 0.547059 (0.109899) with: {'C': 0.1, 'kernel': 'poly'}\n",
      "#39 0.561397 (0.129034) with: {'C': 0.1, 'kernel': 'rbf'}\n",
      "#36 0.709926 (0.074196) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "#27 0.746324 (0.098677) with: {'C': 0.3, 'kernel': 'linear'}\n",
      "#38 0.648529 (0.143544) with: {'C': 0.3, 'kernel': 'poly'}\n",
      "#15 0.771691 (0.093305) with: {'C': 0.3, 'kernel': 'rbf'}\n",
      "#30 0.734926 (0.067380) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
      "#22 0.758456 (0.102468) with: {'C': 0.5, 'kernel': 'linear'}\n",
      "#37 0.673897 (0.115935) with: {'C': 0.5, 'kernel': 'poly'}\n",
      "#13 0.788235 (0.064190) with: {'C': 0.5, 'kernel': 'rbf'}\n",
      "#25 0.747059 (0.057658) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "#24 0.758088 (0.092026) with: {'C': 0.7, 'kernel': 'linear'}\n",
      "#27 0.746324 (0.129754) with: {'C': 0.7, 'kernel': 'poly'}\n",
      "#11 0.818382 (0.091900) with: {'C': 0.7, 'kernel': 'rbf'}\n",
      "#16 0.770956 (0.059555) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
      "#26 0.746691 (0.088716) with: {'C': 0.9, 'kernel': 'linear'}\n",
      "#14 0.776103 (0.118568) with: {'C': 0.9, 'kernel': 'poly'}\n",
      "#9 0.830147 (0.087956) with: {'C': 0.9, 'kernel': 'rbf'}\n",
      "#18 0.764706 (0.065189) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
      "#29 0.740441 (0.094668) with: {'C': 1.0, 'kernel': 'linear'}\n",
      "#12 0.806618 (0.101742) with: {'C': 1.0, 'kernel': 'poly'}\n",
      "#9 0.830147 (0.083397) with: {'C': 1.0, 'kernel': 'rbf'}\n",
      "#31 0.734559 (0.077726) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "#22 0.758456 (0.102468) with: {'C': 1.3, 'kernel': 'linear'}\n",
      "#7 0.836397 (0.096184) with: {'C': 1.3, 'kernel': 'poly'}\n",
      "#4 0.854044 (0.084735) with: {'C': 1.3, 'kernel': 'rbf'}\n",
      "#33 0.728309 (0.051482) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
      "#19 0.764338 (0.107595) with: {'C': 1.5, 'kernel': 'linear'}\n",
      "#5 0.842279 (0.112364) with: {'C': 1.5, 'kernel': 'poly'}\n",
      "#3 0.866176 (0.091458) with: {'C': 1.5, 'kernel': 'rbf'}\n",
      "#32 0.733456 (0.081602) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
      "#19 0.764338 (0.107595) with: {'C': 1.7, 'kernel': 'linear'}\n",
      "#7 0.836397 (0.111649) with: {'C': 1.7, 'kernel': 'poly'}\n",
      "#1 0.872426 (0.097562) with: {'C': 1.7, 'kernel': 'rbf'}\n",
      "#35 0.721324 (0.082779) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
      "#19 0.764338 (0.107595) with: {'C': 2.0, 'kernel': 'linear'}\n",
      "#6 0.836765 (0.107202) with: {'C': 2.0, 'kernel': 'poly'}\n",
      "#1 0.872426 (0.097562) with: {'C': 2.0, 'kernel': 'rbf'}\n",
      "#34 0.721691 (0.092965) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "# Boosting methods\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "ensembles.append(('RF', RandomForestClassifier()))\n",
    "ensembles.append(('ET', ExtraTreesClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.819118 (0.067367)\n",
      "GBM: 0.824265 (0.080460)\n",
      "RF: 0.824632 (0.083027)\n",
      "ET: 0.866176 (0.109559)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.7, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaled = scaler.transform(X_train)\n",
    "model = SVC(C=1.7)\n",
    "model.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n",
      "[[25  2]\n",
      " [ 1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.96      0.93      0.94        27\n",
      "           R       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.92      0.93      0.92        42\n",
      "weighted avg       0.93      0.93      0.93        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

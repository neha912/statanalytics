{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "from sklearn import  metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knnc\n",
    "from sklearn.naive_bayes import GaussianNB as gnb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sonar.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.columns[len(data.columns)-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1553</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "38   0.0123  0.0022  0.0196  0.0206  0.0180  0.0492  0.0033  0.0398  0.0791   \n",
       "149  0.0207  0.0535  0.0334  0.0818  0.0740  0.0324  0.0918  0.1070  0.1553   \n",
       "118  0.0363  0.0478  0.0298  0.0210  0.1409  0.1916  0.1349  0.1613  0.1703   \n",
       "47   0.0373  0.0281  0.0232  0.0225  0.0179  0.0733  0.0841  0.1031  0.0993   \n",
       "151  0.0231  0.0315  0.0170  0.0226  0.0410  0.0116  0.0223  0.0805  0.2365   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "92   0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "160  0.0258  0.0433  0.0547  0.0681  0.0784  0.1250  0.1296  0.1729  0.2794   \n",
       "69   0.0216  0.0215  0.0273  0.0139  0.0357  0.0785  0.0906  0.0908  0.1151   \n",
       "144  0.0299  0.0688  0.0992  0.1021  0.0800  0.0629  0.0130  0.0813  0.1761   \n",
       "58   0.0225  0.0019  0.0075  0.0097  0.0445  0.0906  0.0889  0.0655  0.1624   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "38   0.0475  ...  0.0149  0.0125  0.0134  0.0026  0.0038  0.0018  0.0113   \n",
       "149  0.1234  ...  0.0171  0.0033  0.0050  0.0190  0.0103  0.0121  0.0042   \n",
       "118  0.1444  ...  0.0250  0.0115  0.0190  0.0055  0.0096  0.0050  0.0066   \n",
       "47   0.0802  ...  0.0066  0.0008  0.0045  0.0024  0.0006  0.0073  0.0096   \n",
       "151  0.2461  ...  0.0151  0.0125  0.0036  0.0123  0.0043  0.0114  0.0052   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "92   0.1630  ...  0.0132  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035   \n",
       "160  0.2954  ...  0.0121  0.0091  0.0062  0.0019  0.0045  0.0079  0.0031   \n",
       "69   0.0973  ...  0.0082  0.0140  0.0044  0.0052  0.0073  0.0021  0.0047   \n",
       "144  0.0998  ...  0.0342  0.0459  0.0277  0.0172  0.0087  0.0046  0.0203   \n",
       "58   0.1452  ...  0.0051  0.0034  0.0129  0.0100  0.0044  0.0057  0.0030   \n",
       "\n",
       "         57      58      59  \n",
       "38   0.0058  0.0047  0.0071  \n",
       "149  0.0090  0.0070  0.0099  \n",
       "118  0.0114  0.0073  0.0033  \n",
       "47   0.0054  0.0085  0.0060  \n",
       "151  0.0091  0.0008  0.0092  \n",
       "..      ...     ...     ...  \n",
       "92   0.0008  0.0044  0.0077  \n",
       "160  0.0063  0.0048  0.0050  \n",
       "69   0.0024  0.0009  0.0017  \n",
       "144  0.0130  0.0115  0.0015  \n",
       "58   0.0035  0.0021  0.0027  \n",
       "\n",
       "[208 rows x 60 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(frac =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.22,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    knnc(),\n",
    "    dtc(),\n",
    "    SVC(),\n",
    "    SVC(kernel='linear'),\n",
    "    gnb()\n",
    "]\n",
    "classifier_names = [\n",
    "    'K nearest neighbors',\n",
    "    'Decision Tree Classifier',\n",
    "    'SVM classifier with RBF kernel',\n",
    "    'SVM classifier with linear kernel',\n",
    "    'Gaussian Naive Bayes'\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K nearest neighbors  mean accuracy:  75.919 % std:  0.885 %\n",
      "Decision Tree Classifier  mean accuracy:  74.044 % std:  0.299 %\n",
      "SVM classifier with RBF kernel  mean accuracy:  75.993 % std:  1.282 %\n",
      "SVM classifier with linear kernel  mean accuracy:  72.831 % std:  0.17 %\n",
      "Gaussian Naive Bayes  mean accuracy:  68.971 % std:  1.62 %\n"
     ]
    }
   ],
   "source": [
    "for clf, clf_name in zip(classifiers, classifier_names):\n",
    "    cv_scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "    \n",
    "    print(clf_name, ' mean accuracy: ', round(cv_scores.mean()*100, 3), '% std: ', round(cv_scores.var()*100, 3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:-1].astype(float)\n",
    "Y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, set_option\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check some algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.769485 (0.100510)\n",
      "LDA: 0.752574 (0.107741)\n",
      "KNN: 0.808088 (0.067507)\n",
      "CART: 0.723162 (0.113078)\n",
      "NB: 0.642647 (0.149464)\n",
      "SVM: 0.776471 (0.090411)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.868015 using {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.872426 using {'C': 1.7, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#17 0.770221 (0.095521) with: {'C': 0.1, 'kernel': 'linear'}\n",
      "#40 0.547059 (0.109899) with: {'C': 0.1, 'kernel': 'poly'}\n",
      "#39 0.561397 (0.129034) with: {'C': 0.1, 'kernel': 'rbf'}\n",
      "#36 0.709926 (0.074196) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "#27 0.746324 (0.098677) with: {'C': 0.3, 'kernel': 'linear'}\n",
      "#38 0.648529 (0.143544) with: {'C': 0.3, 'kernel': 'poly'}\n",
      "#15 0.771691 (0.093305) with: {'C': 0.3, 'kernel': 'rbf'}\n",
      "#30 0.734926 (0.067380) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
      "#22 0.758456 (0.102468) with: {'C': 0.5, 'kernel': 'linear'}\n",
      "#37 0.673897 (0.115935) with: {'C': 0.5, 'kernel': 'poly'}\n",
      "#13 0.788235 (0.064190) with: {'C': 0.5, 'kernel': 'rbf'}\n",
      "#25 0.747059 (0.057658) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "#24 0.758088 (0.092026) with: {'C': 0.7, 'kernel': 'linear'}\n",
      "#27 0.746324 (0.129754) with: {'C': 0.7, 'kernel': 'poly'}\n",
      "#11 0.818382 (0.091900) with: {'C': 0.7, 'kernel': 'rbf'}\n",
      "#16 0.770956 (0.059555) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
      "#26 0.746691 (0.088716) with: {'C': 0.9, 'kernel': 'linear'}\n",
      "#14 0.776103 (0.118568) with: {'C': 0.9, 'kernel': 'poly'}\n",
      "#9 0.830147 (0.087956) with: {'C': 0.9, 'kernel': 'rbf'}\n",
      "#18 0.764706 (0.065189) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
      "#29 0.740441 (0.094668) with: {'C': 1.0, 'kernel': 'linear'}\n",
      "#12 0.806618 (0.101742) with: {'C': 1.0, 'kernel': 'poly'}\n",
      "#9 0.830147 (0.083397) with: {'C': 1.0, 'kernel': 'rbf'}\n",
      "#31 0.734559 (0.077726) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "#22 0.758456 (0.102468) with: {'C': 1.3, 'kernel': 'linear'}\n",
      "#7 0.836397 (0.096184) with: {'C': 1.3, 'kernel': 'poly'}\n",
      "#4 0.854044 (0.084735) with: {'C': 1.3, 'kernel': 'rbf'}\n",
      "#33 0.728309 (0.051482) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
      "#19 0.764338 (0.107595) with: {'C': 1.5, 'kernel': 'linear'}\n",
      "#5 0.842279 (0.112364) with: {'C': 1.5, 'kernel': 'poly'}\n",
      "#3 0.866176 (0.091458) with: {'C': 1.5, 'kernel': 'rbf'}\n",
      "#32 0.733456 (0.081602) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
      "#19 0.764338 (0.107595) with: {'C': 1.7, 'kernel': 'linear'}\n",
      "#7 0.836397 (0.111649) with: {'C': 1.7, 'kernel': 'poly'}\n",
      "#1 0.872426 (0.097562) with: {'C': 1.7, 'kernel': 'rbf'}\n",
      "#35 0.721324 (0.082779) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
      "#19 0.764338 (0.107595) with: {'C': 2.0, 'kernel': 'linear'}\n",
      "#6 0.836765 (0.107202) with: {'C': 2.0, 'kernel': 'poly'}\n",
      "#1 0.872426 (0.097562) with: {'C': 2.0, 'kernel': 'rbf'}\n",
      "#34 0.721691 (0.092965) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "# Boosting methods\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "ensembles.append(('RF', RandomForestClassifier()))\n",
    "ensembles.append(('ET', ExtraTreesClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.819118 (0.067367)\n",
      "GBM: 0.847426 (0.111770)\n",
      "RF: 0.800368 (0.087142)\n",
      "ET: 0.890441 (0.072470)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.7, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaled = scaler.transform(X_train)\n",
    "model = SVC(C=1.7)\n",
    "model.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n",
      "[[25  2]\n",
      " [ 1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.93      0.94        27\n",
      "           R       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.92      0.93      0.92        42\n",
      "weighted avg       0.93      0.93      0.93        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
